{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKSOsMw3KIwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0006c924-a921-476b-b086-974d10908da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import os\n",
        "from google.colab import drive \n",
        "import re\n",
        "import zipfile\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/STOR566_FinalProject/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V794x_Q5g-UE"
      },
      "outputs": [],
      "source": [
        "def txt_cleaner(string):\n",
        "    string = re.sub('<[^<]+?>', '', string) #removes html\n",
        "    string = re.sub(r'[^\\w\\s]', '', string) #removes everything but letters/numbers and whitespace\n",
        "    return string.lower() #Makes all characters lowercase\n",
        "    # Should we implement a method to correct mispellings too? Seems like maybe too much effort..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SYo_kqPKZWD"
      },
      "outputs": [],
      "source": [
        "#https://github.com/neilpl24/STOR566/data/IMDB Dataset.csv.zip\n",
        "#https://github.com/neilpl24/STOR566/data/Restaurant_Reviews.tsv\n",
        "\n",
        "url_test = 'https://raw.githubusercontent.com/neilpl24/STOR566/main/data/Restaurant_Reviews.tsv'\n",
        "df_test = pd.read_csv(url_test, sep = '\\t')\n",
        "df_test.rename(columns={'Review':'review', 'Liked':'label'}, inplace=True)\n",
        "df_test[\"review\"] = df_test[\"review\"].apply(txt_cleaner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcxp3q2TbrOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "10535e2c-776b-481d-b00b-0e89fc3fb00e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  label\n",
              "0                               wow loved this place      1\n",
              "1                                  crust is not good      0\n",
              "2           not tasty and the texture was just nasty      0\n",
              "3  stopped by during the late may bank holiday of...      1\n",
              "4  the selection on the menu was great and so wer...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49f623f7-8c1c-4a32-af5b-819a14e1af69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow loved this place</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crust is not good</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not tasty and the texture was just nasty</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stopped by during the late may bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49f623f7-8c1c-4a32-af5b-819a14e1af69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49f623f7-8c1c-4a32-af5b-819a14e1af69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49f623f7-8c1c-4a32-af5b-819a14e1af69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHubk8F-TugF"
      },
      "outputs": [],
      "source": [
        "url_train = \"https://raw.githubusercontent.com/neilpl24/STOR566/main/data/IMDB_Dataset.csv\"\n",
        "df_train = pd.read_csv(url_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_0cLhc3aQC8"
      },
      "outputs": [],
      "source": [
        "# Workaround for if Github link isn't working - put .zip file in your working google drive directory\n",
        "\n",
        "# import zipfile\n",
        "\n",
        "# zf = zipfile.ZipFile('IMDB Dataset.csv.zip') \n",
        "# df_train = pd.read_csv(zf.open('IMDB Dataset.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m4gcwOtbjC7"
      },
      "outputs": [],
      "source": [
        "df_train[\"label\"] = 1\n",
        "for i in range(len(df_train)):\n",
        "    if df_train.loc[i, \"sentiment\"] == \"negative\":\n",
        "        df_train.loc[i, \"label\"] = 0\n",
        "df_train.drop(columns = [\"sentiment\"], inplace=True)\n",
        "df_train[\"review\"] = df_train[\"review\"].apply(txt_cleaner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCdiIbXkg14R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4b3ae6ad-23b7-445a-9e00-e9f97ddb113d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  label\n",
              "0  one of the other reviewers has mentioned that ...      1\n",
              "1  a wonderful little production the filming tech...      1\n",
              "2  i thought this was a wonderful way to spend ti...      1\n",
              "3  basically theres a family where a little boy j...      0\n",
              "4  petter matteis love in the time of money is a ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1caab303-fb34-4270-a47a-f2733bb9f5d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a wonderful little production the filming tech...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically theres a family where a little boy j...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter matteis love in the time of money is a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1caab303-fb34-4270-a47a-f2733bb9f5d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1caab303-fb34-4270-a47a-f2733bb9f5d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1caab303-fb34-4270-a47a-f2733bb9f5d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpA4fceImvMg"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    \"\"\"Text dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, df, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df (DataFrame): dataframe to work with.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        label = self.df.iloc[idx, 1]\n",
        "        review = self.df.iloc[idx, 0]\n",
        "        #review = np.array([review])\n",
        "        #sample = {'review': review, 'label': label}\n",
        "\n",
        "        if self.transform:\n",
        "            review = self.transform(review)\n",
        "\n",
        "        return review, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yaTudeLc3nF"
      },
      "outputs": [],
      "source": [
        "# Padding dataFrame vals to length 256 - either cutting to that length or 0-padding up to it\n",
        "def padding(df, pad_len):\n",
        "    '''Zero Pad tokens listed under \"review\" in a dataset to a pad length and return new dataset'''\n",
        "    new_df = df[[\"label\"]]\n",
        "    features = []\n",
        "    for i in range(len(df)):\n",
        "        feature = np.zeros(pad_len, dtype=int)\n",
        "        for v in range(min(pad_len, len(df.loc[i, \"review\"]))):\n",
        "            feature[v] = df.loc[i, \"review\"][v]\n",
        "        features.append(feature)\n",
        "    new_df['review'] = [features[j] for j in new_df.index]\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4SyFCuCpuUP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "79b98be3-1a5b-4941-f9c0-7a3c19b20076"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-83cedb54de0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mvocab_later\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myield_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mvocab_later\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_later\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab/vocab_factory.py\u001b[0m in \u001b[0;36mbuild_vocab_from_iterator\u001b[0;34m(iterator, min_freq, specials, special_first, max_tokens)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-83cedb54de0a>\u001b[0m in \u001b[0;36myield_tokens\u001b[0;34m(data_iter)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0myield_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py\u001b[0m in \u001b[0;36m_basic_english_normalize\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpattern_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplaced_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_patterns_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplaced_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'lower'"
          ]
        }
      ],
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for batch, _ in data_iter:\n",
        "        yield tokenizer(batch)\n",
        "\n",
        "td = TextDataset(df = df_train)\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "train_it = iter(td)\n",
        "\n",
        "vocab_later = build_vocab_from_iterator(yield_tokens(train_it), specials=[\"<unk>\"])\n",
        "vocab_later.set_default_index(vocab_later[\"<unk>\"])\n",
        "\n",
        "def processing_func(train_df_orig, test_df_orig):\n",
        "    train_df = train_df_orig\n",
        "    test_df = test_df_orig\n",
        "\n",
        "    train_dataset = TextDataset(df = train_df)\n",
        "\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "    train_iter = iter(train_dataset)\n",
        "\n",
        "    vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "    train_df[\"tokens\"] = train_df[\"review\"].apply(lambda x: vocab(tokenizer(x)))\n",
        "    train_df.drop([\"review\"], axis = 1, inplace=True)\n",
        "    train_df.rename(columns = {\"tokens\":\"review\"}, inplace=True)\n",
        "    train_df = train_df[[\"review\", \"label\"]]\n",
        "\n",
        "    test_df[\"tokens\"] = test_df[\"review\"].apply(lambda x: vocab(tokenizer(x)))\n",
        "    test_df.drop([\"review\"], axis = 1, inplace=True)\n",
        "    test_df.rename(columns = {\"tokens\":\"review\"}, inplace=True)\n",
        "    test_df = test_df[[\"review\", \"label\"]]    \n",
        "\n",
        "    train_df = padding(train_df, 256)\n",
        "    test_df = padding(test_df, 256)\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF1MYbsMrUQH"
      },
      "outputs": [],
      "source": [
        "df_train_tokenized, df_test_tokenized = processing_func(df_train, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQwwkp72sdJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5a475f-efea-450c-9605-629c5dfcb4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "train_iter = TextDataset(df = df_train_tokenized)\n",
        "train_dataloader = DataLoader(train_iter, batch_size=64, shuffle=False)\n",
        "test_iter = TextDataset(df_test_tokenized)\n",
        "test_dataloader = DataLoader(test_iter, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxpjVw_Q1PeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46891fbd-de90-4087-acbd-707dc88b5b75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "         0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "         1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]),\n",
              " tensor([[   27,     4,     1,  ...,    19,   610,     2],\n",
              "         [    3,   382,   113,  ...,     0,     0,     0],\n",
              "         [    9,   191,    10,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  196,    39,   275,  ...,     0,     0,     0],\n",
              "         [   37,   619, 36926,  ...,     0,     0,     0],\n",
              "         [ 1425,   105,   347,  ...,     0,     0,     0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2js__FerXrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3d2524-2d31-4be6-dee5-8e42338a7067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
            "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
            "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]), tensor([[   27,     4,     1,  ...,    19,   610,     2],\n",
            "        [    3,   382,   113,  ...,     0,     0,     0],\n",
            "        [    9,   191,    10,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  196,    39,   275,  ...,     0,     0,     0],\n",
            "        [   37,   619, 36926,  ...,     0,     0,     0],\n",
            "        [ 1425,   105,   347,  ...,     0,     0,     0]])]\n"
          ]
        }
      ],
      "source": [
        "for zero, batch in enumerate(train_dataloader):\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOnzPNimKvGp"
      },
      "source": [
        "So as you can kind of see above, the way the batches seem to be coming out is as a list of (0, tensor), where the zero is just a placeholder (not sure why it's there) and tensor that contains 2 subtensors. If you index as \"zero, batch in enumerate(dataloader)\", during training, you'll get the batch in the tensor. The tensor contents are as follows:\n",
        "\n",
        "1st sub-tensor: The labels for the batch; 1 is positive, 0 is negative.\n",
        "\n",
        "2nd sub-tensor: A list of lists, where each list is a length-256 0-padded tokenized review that corresponds to the order of the labels.\n",
        "\n",
        "This means that each observation can be represented as follows:\n",
        "\n",
        "Observation i in batch:\n",
        "\n",
        "reviews=batch[1]\n",
        "\n",
        "labels=batch[0]\n",
        "\n",
        "review_i = reviews[i]\n",
        "\n",
        "label_i = labels[i]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_dataloader:\n",
        "  print(data)\n",
        "  break"
      ],
      "metadata": {
        "id": "_3SgznvZKlEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f494732f-3270-465b-c157-4dbf63d42dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
            "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
            "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]), tensor([[   27,     4,     1,  ...,    19,   610,     2],\n",
            "        [    3,   382,   113,  ...,     0,     0,     0],\n",
            "        [    9,   191,    10,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  196,    39,   275,  ...,     0,     0,     0],\n",
            "        [   37,   619, 36926,  ...,     0,     0,     0],\n",
            "        [ 1425,   105,   347,  ...,     0,     0,     0]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext.transforms as T\n",
        "import torchtext.functional as F\n",
        "from torchtext.datasets import SST2\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SentimentalGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, output_dim, embedding_dim, hidden_dim, n_layers, \n",
        "                 drop_prob=0.5):    \n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # Embedding and GRU layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, \n",
        "                         batch_first=True)\n",
        "        \n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        \n",
        "        # Linear and sigmoid layer\n",
        "        self.fc1 = nn.Linear(hidden_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 16)\n",
        "        self.fc3 = nn.Linear(16, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size()\n",
        "        \n",
        "        # Embedding and GRU output\n",
        "        embedded = self.embedding(x)\n",
        "        gru_out, hidden = self.gru(embedded, hidden)\n",
        "        \n",
        "        # Stack the GRU output\n",
        "        gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # Dropout and fully connected layers, with sigmoid transform\n",
        "        out = self.dropout(gru_out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc3(out)\n",
        "        prob_out = self.sigmoid(out)\n",
        "        \n",
        "        prob_out = prob_out.view(batch_size, -1)\n",
        "        prob_out = prob_out[:, -1]\n",
        "        \n",
        "        return prob_out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"Initialize Hidden STATE\"\"\"\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n",
        "\n",
        "# Initialize model\n",
        "gru = GRUModel(256, 128, 3, 1, 0.2)\n",
        "h = gru.init_hidden()\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 2\n",
        "lr = 0.01\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = optim.Adam(gru.parameters(), lr=lr)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "M-SIFjBJG68C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_sz = vocab_later.__len__() + 1\n",
        "output_sz = 1\n",
        "embed_dim = 400\n",
        "h_dim = 256\n",
        "n_layer = 2\n",
        "\n",
        "\n",
        "lstm_mod = SentimentalGRU(vocab_sz, output_sz, embed_dim, h_dim, n_layer)\n",
        "\n",
        "lr = 0.001\n",
        "loss_func = nn.BCELoss()\n",
        "optim = torch.optim.Adam(lstm_mod.parameters(), lr=lr)\n",
        "num_epochs = 10\n",
        "clip=5\n",
        "batch_size = 8\n",
        "\n",
        "lstm_mod = lstm_mod.to(device)\n",
        "\n",
        "lstm_mod.train()\n",
        "\n",
        "epochs = []\n",
        "epoch_test_losses = []\n",
        "epoch_train_losses = []\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    print(\"Starting epoch #\", e)\n",
        "    h = lstm_mod.init_hidden(batch_size)\n",
        "    counter = 0\n",
        "    for zero, batch in enumerate(train_dataloader):\n",
        "        labels = batch[0].to(device)\n",
        "        inputs = batch[1].to(device)\n",
        "        if (len(labels) != 8):\n",
        "            print(\"Encountered shorter batch at batch #\", counter)\n",
        "            break #end of batchs, just leave the last few observations\n",
        "        h = tuple([each.data for each in h])\n",
        "        lstm_mod.zero_grad()\n",
        "        output, h = lstm_mod(inputs, h)\n",
        "        loss = loss_func(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(lstm_mod.parameters(), clip)\n",
        "        optim.step()\n",
        "        counter += 1\n",
        "\n",
        "    epochs.append(e)\n",
        "    test_outputs = []\n",
        "    for zero, batch in enumerate(test_dataloader): \n",
        "        labels = batch[0].to(device)\n",
        "        inputs = batch[1].to(device)\n",
        "        if (len(labels) != 8):\n",
        "            break\n",
        "        h = tuple([each.data for each in h])\n",
        "        output, h = lstm_mod(inputs, h)\n",
        "        loss = loss_func(output.squeeze(), labels.float())\n",
        "        test_outputs.append(float(loss))\n",
        "\n",
        "    epoch_test_losses.append(np.mean(test_outputs))\n",
        "\n",
        "    train_outputs = []\n",
        "    for zero, batch in enumerate(train_dataloader): \n",
        "        labels = batch[0].to(device)\n",
        "        inputs = batch[1].to(device)\n",
        "        if (len(labels) != 8):\n",
        "            break\n",
        "        h = tuple([each.data for each in h])\n",
        "        output, h = lstm_mod(inputs, h)\n",
        "        loss = loss_func(output.squeeze(), labels.float())\n",
        "        train_outputs.append(float(loss))\n",
        "\n",
        "    epoch_train_losses.append(np.mean(train_outputs))"
      ],
      "metadata": {
        "id": "dh8usjv8KdQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1a9dcb-34d7-4a43-dca8-7adde32978fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2 Done, Total Training Loss: 0.6963470976828309, Total Test Loss: 0.6929317153990269\n",
            "Epoch 2/2 Done, Total Training Loss: 0.6969500897485582, Total Test Loss: 0.6946677640080452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "for data in test_dataloader:\n",
        "    labels = data[0].unsqueeze(1).float()\n",
        "    sents = data[1].float()\n",
        "    preds, _ = gru(sents, h)\n",
        "    total += labels.size(0)\n",
        "    correct += (preds.round() == labels).sum()\n",
        "  \n",
        "print(f\"Test Accuracy = {correct / total}\")"
      ],
      "metadata": {
        "id": "b5KtMoq3KdBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0741af-9325-4e3f-8240-ea745fdf6029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy = 0.4959999918937683\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}